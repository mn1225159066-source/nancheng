import streamlit as st
import sys
import os
import browser_cookie3

# Add project root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from src.core.scraper import FanqieScraper
from src.core.utils import clean_filename, UA_CHROME, UA_EDGE, UA_FIREFOX, UA_MACOS_CHROME, UA_SAFARI, log_debug
import platform
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

st.set_page_config(page_title="å—åŸæ´‹æŸ¿å­å°è¯´ä¸‹è½½å™¨", page_icon="ğŸ…")

st.title("ğŸ… å—åŸæ´‹æŸ¿å­å°è¯´ä¸‹è½½å™¨")

# Sidebar for app control
# Removed as per user request
# with st.sidebar:
#     st.header("ç¨‹åºæ§åˆ¶")
#     if st.button("ğŸ”´ å…³é—­ç¨‹åº"):
#         st.warning("æ­£åœ¨å…³é—­ç¨‹åº...")
#         os._exit(0)
#     st.info("å¦‚æœä¸‹è½½å‡ºç°é—®é¢˜ï¼Œè¯·å…ˆå°è¯•ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å½»åº•å…³é—­ç¨‹åºï¼Œç„¶åé‡æ–°æ‰“å¼€ã€‚")

st.markdown("""
**è¯´æ˜**: 
1. è¾“å…¥å°è¯´ä¸»é¡µé“¾æ¥ã€‚
2. ç‚¹å‡»â€œè·å–ä¿¡æ¯â€æŸ¥çœ‹å°è¯´è¯¦æƒ…ã€‚
3. **å¦‚æœä¸‹è½½ VIP ç« èŠ‚å¤±è´¥ï¼Œè¯·å°è¯•å…ˆåœ¨æµè§ˆå™¨æ‰“å¼€ä»»æ„ä¸€ç«  VIP ç« èŠ‚ï¼Œç„¶åå…³é—­æµè§ˆå™¨å†é‡è¯•ã€‚**
""")

def get_browser_cookies(domain_name):
    """Try to load cookies from common browsers"""
    log_debug(f"Attempting to load cookies for domain: {domain_name}")
    cookies = []
    # Try Chrome
    try:
        log_debug("Checking Chrome...")
        cj = browser_cookie3.chrome(domain_name=domain_name)
        if len(cj) > 0:
            log_debug(f"Found {len(cj)} cookies in Chrome")
            cookies.append(("Chrome", cj))
        else:
             log_debug("Chrome cookies empty for domain")
    except Exception as e:
        log_debug(f"Chrome cookie error: {e}")
    
    # Try Edge
    try:
        log_debug("Checking Edge...")
        cj = browser_cookie3.edge(domain_name=domain_name)
        if len(cj) > 0:
            log_debug(f"Found {len(cj)} cookies in Edge")
            cookies.append(("Edge", cj))
        else:
             log_debug("Edge cookies empty for domain")
    except Exception as e:
        log_debug(f"Edge cookie error: {e}")
        
    # Try Firefox
    try:
        log_debug("Checking Firefox...")
        cj = browser_cookie3.firefox(domain_name=domain_name)
        if len(cj) > 0:
             log_debug(f"Found {len(cj)} cookies in Firefox")
             cookies.append(("Firefox", cj))
        else:
             log_debug("Firefox cookies empty for domain")
    except Exception as e:
        log_debug(f"Firefox cookie error: {e}")
        
    return cookies

def format_cookie_str(cookie_jar):
    return "; ".join([f"{c.name}={c.value}" for c in cookie_jar])

url = st.text_input("å°è¯´ä¸»é¡µé“¾æ¥", placeholder="https://fanqienovel.com/page/...")

# Cookie handling
st.markdown("### ğŸ”‘ VIP ç™»å½• (å¯é€‰)")

# Add Browser Selection
browser_type = st.selectbox(
    "Cookie æ¥æºæµè§ˆå™¨ (è¯·é€‰æ‹©æ‚¨è·å– Cookie çš„æµè§ˆå™¨)",
    ["Chrome / Edge", "Safari", "Firefox"],
    help="VIP ç« èŠ‚ä¸‹è½½å¤±è´¥æ—¶ï¼Œè¯·ç¡®ä¿æ­¤é€‰é¡¹ä¸æ‚¨è·å– Cookie çš„æµè§ˆå™¨ä¸€è‡´"
)

col_c1, col_c2 = st.columns([3, 1])

with col_c1:
    cookie_str = st.text_input("Cookie (æ‰‹åŠ¨è¾“å…¥)", type="password", help="åœ¨æµè§ˆå™¨æ§åˆ¶å°è¾“å…¥ document.cookie è·å–")

with col_c2:
    st.write("") # Spacer
    st.write("") 
    if st.button("ğŸ–¥ï¸ è‡ªåŠ¨è·å– Cookie"):
        with st.spinner("æ­£åœ¨ä»æµè§ˆå™¨è·å– Cookie..."):
            found_cookies = get_browser_cookies("fanqienovel.com")
            if found_cookies:
                # Prioritize Chrome or first found
                name, jar = found_cookies[0]
                cookie_str_val = format_cookie_str(jar)
                
                # Determine User-Agent based on browser
                ua = None
                if name == "Chrome":
                    if platform.system() == 'Darwin':
                        ua = UA_MACOS_CHROME
                    else:
                        ua = UA_CHROME
                elif name == "Edge":
                    ua = UA_EDGE
                elif name == "Firefox":
                    ua = UA_FIREFOX

                # We can't update text_input programmatically easily without rerun or session state
                # But we can store it in session state and reload
                st.session_state['auto_cookie'] = cookie_str_val
                st.session_state['auto_ua'] = ua
                st.success(f"å·²ä» {name} è·å– Cookie! (é•¿åº¦: {len(cookie_str_val)} å­—ç¬¦)")
            else:
                st.error("æœªåœ¨å¸¸ç”¨æµè§ˆå™¨(Chrome/Edge)ä¸­æ‰¾åˆ°ç•ªèŒ„å°è¯´ Cookieï¼Œè¯·å…ˆåœ¨æµè§ˆå™¨ç™»å½•ç•ªèŒ„å°è¯´ç½‘ã€‚")
                st.warning("å¦‚æœæµè§ˆå™¨å·²æ‰“å¼€ï¼Œè¯·å°è¯•å…³é—­æµè§ˆå™¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥æ˜¯å¦å·²ç™»å½•ã€‚")

# Use session state cookie if available and input is empty
if 'auto_cookie' in st.session_state and not cookie_str:
    cookie_str = st.session_state['auto_cookie']
    st.info("å·²è‡ªåŠ¨å¡«å…… Cookie")

if 'novel_data' not in st.session_state:
    st.session_state.novel_data = None
if 'chapters' not in st.session_state:
    st.session_state.chapters = []

if st.button("è·å–ä¿¡æ¯"):
    if not url:
        st.error("è¯·è¾“å…¥é“¾æ¥")
    else:
        with st.spinner("æ­£åœ¨è·å–å°è¯´ä¿¡æ¯..."):
            user_agent = st.session_state.get('auto_ua')
            if not user_agent:
                if browser_type == "Safari":
                    user_agent = UA_SAFARI
                elif browser_type == "Firefox":
                    user_agent = UA_FIREFOX
                else:
                    user_agent = UA_MACOS_CHROME if platform.system() == 'Darwin' else UA_CHROME
            
            scraper = FanqieScraper(cookie_str, user_agent)
            metadata = scraper.get_novel_metadata(url)
            if metadata:
                st.session_state.novel_data = metadata
                st.session_state.chapters = scraper.get_chapter_list(url)
                st.success("è·å–æˆåŠŸï¼")
            else:
                st.error("è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æˆ–ç½‘ç»œã€‚")

if st.session_state.novel_data:
    novel = st.session_state.novel_data
    st.divider()
    col1, col2 = st.columns([1, 3])
    with col1:
        if novel.get('cover_url'):
            st.image(novel['cover_url'], width=150)
    with col2:
        st.subheader(novel['title'])
        st.write(f"**ä½œè€…**: {novel['author']}")
        st.write(f"**ç« èŠ‚æ•°**: {len(st.session_state.chapters)}")

    st.divider()
    
    # Range selection
    chapter_options = [f"{i+1}. {c['title']}" for i, c in enumerate(st.session_state.chapters)]
    
    # Select All Checkbox
    select_all = st.checkbox("å…¨é€‰æ‰€æœ‰ç« èŠ‚", value=True)
    
    if select_all:
        selected_chapters = st.multiselect("é€‰æ‹©ç« èŠ‚", chapter_options, default=chapter_options)
    else:
        selected_chapters = st.multiselect("é€‰æ‹©ç« èŠ‚", chapter_options)
    
    if st.button("å¼€å§‹ä¸‹è½½"):
        user_agent = st.session_state.get('auto_ua')
        if not user_agent:
            if browser_type == "Safari":
                user_agent = UA_SAFARI
            elif browser_type == "Firefox":
                user_agent = UA_FIREFOX
            else:
                user_agent = UA_MACOS_CHROME if platform.system() == 'Darwin' else UA_CHROME
                
        scraper = FanqieScraper(cookie_str, user_agent)
        
        # Determine chapters to download
        chapters_to_download = []
        if not selected_chapters:
            # Fallback if somehow nothing selected but list is empty, though 'select all' handles this
            chapters_to_download = [] 
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç« èŠ‚")
        else:
            indices = [int(s.split('.')[0]) - 1 for s in selected_chapters]
            chapters_to_download = [st.session_state.chapters[i] for i in sorted(indices)]

        if chapters_to_download:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Prepare result list
            downloaded_content = []
            
            completed_count = 0
            failed_count = 0
            
            import random
            
            # Single-threaded download
            for i, chapter in enumerate(chapters_to_download):
                try:
                    # Random delay to avoid detection
                    time.sleep(random.uniform(0.5, 1.5))
                    
                    content = scraper.get_chapter_content(chapter['url'])
                    if content:
                        content['title'] = chapter['title']
                        downloaded_content.append(content)
                        completed_count += 1
                    else:
                        failed_count += 1
                except Exception as e:
                    log_debug(f"Error fetching {chapter['title']}: {e}")
                    failed_count += 1
                
                # Update progress
                progress = (i + 1) / len(chapters_to_download)
                progress_bar.progress(progress)
                status_text.text(f"è¿›åº¦: {i + 1}/{len(chapters_to_download)} (æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count})")
            
            # Filter out failed downloads (already filtered by append logic)
            valid_content = downloaded_content
            
            if not valid_content:
                st.error("æ‰€æœ‰ç« èŠ‚ä¸‹è½½å¤±è´¥ï¼è¯·æ£€æŸ¥ï¼š\n1. ç½‘ç»œè¿æ¥\n2. æ˜¯å¦éœ€è¦æ›´æ–° Cookie (VIPç« èŠ‚)")
                status_text.text("ä¸‹è½½å¤±è´¥")
            else:
                if failed_count > 0:
                    st.warning(f"ä¸‹è½½å®Œæˆï¼Œä½†æœ‰ {failed_count} ä¸ªç« èŠ‚å¤±è´¥ã€‚")
                else:
                    st.success("æ‰€æœ‰ç« èŠ‚ä¸‹è½½å®Œæˆï¼")
                
                status_text.text("æ­£åœ¨ç”Ÿæˆæ–‡ä»¶...")
                
                filename = clean_filename(novel['title'])
                
                file_content = scraper.generate_txt(novel, valid_content)
                file_ext = "txt"
                mime_type = "text/plain"
                    
                # Auto-save to Desktop
                try:
                    desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
                    save_path = os.path.join(desktop_path, f"{filename}.{file_ext}")
                    with open(save_path, "w", encoding="utf-8") as f:
                        f.write(file_content)
                    st.success(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°æ¡Œé¢: **{save_path}**")
                except Exception as e:
                    st.error(f"è‡ªåŠ¨ä¿å­˜åˆ°æ¡Œé¢å¤±è´¥: {e}")

                st.download_button(
                    label=f"ç‚¹å‡»ä¸‹è½½ {file_ext.upper()} æ–‡ä»¶ (å¦å­˜ä¸º)",
                    data=file_content,
                    file_name=f"{filename}.{file_ext}",
                    mime=mime_type
                )
                st.balloons()
